2:I[2972,["972","static/chunks/972-edd2ee9795e590ec.js","931","static/chunks/app/page-d945f7a24654736b.js"],""]
3:I[8599,["972","static/chunks/972-edd2ee9795e590ec.js","598","static/chunks/598-ebaef4f280efd328.js","185","static/chunks/app/layout-eb753ae0993d2b16.js"],"Navigation"]
4:I[4707,[],""]
5:I[6423,[],""]
0:["j5DB29rJCqEgUVbBRHX-s",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","div",null,{"className":"pt-32 pb-16","children":["$","div",null,{"className":"container space-y-32","children":[["$","section",null,{"className":"max-w-4xl","children":["$","h1",null,{"className":"text-6xl font-bold mb-8","children":["Hi! I'm ",["$","span",null,{"className":"gradient-text","children":"Aya Oshima"}],", an AI engineer based in New York."]}]}],["$","section",null,{"className":"space-y-8","children":[["$","h2",null,{"className":"text-2xl font-semibold","children":"Selected Work"}],["$","div",null,{"className":"p-6 rounded-lg border bg-card hover-lift colorful-border flex flex-col md:flex-row gap-4","children":[["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Thesis: Dimensional Reduction Techniques for Neural Data"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Explored dimensional reduction techniques (PCA, TCA) applied to large-scale neural datasets. Conducted analysis on complex neural patterns, providing insights into brain activity and computational neuroscience, under the guidance of Prof. Robert C. Froemke."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PCA"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"TCA"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computational Neuroscience"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Data Analysis"}]]}]]}],["$","div",null,{"className":"flex flex-col flex-1 gap-4","children":[["$","img",null,{"src":"/images/thesis_demo.jpg","alt":"Thesis Image 1","className":"w-full h-auto rounded-lg shadow-md"}],["$","img",null,{"src":"/images/thesis_demo_paper1.jpg","alt":"Thesis Image 2","className":"w-full h-auto rounded-lg shadow-md"}]]}]]}],["$","div",null,{"className":"grid gap-8 md:grid-cols-2","children":[["$","$L2","0",{"href":"https://github.com/aya0221/Neural-Symbolic-VQA-Sort-of-CLEVR","className":"group p-6 rounded-lg border bg-card hover-lift colorful-border","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Neural-Symbolic VQA"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Designed a multi-modal AI system integrating computer vision, NLP, and symbolic reasoning to enhance visual question answering on the Sort-of-CLEVR dataset. Leveraged PyTorch to implement CNNs for image processing and integrated symbolic reasoning to provide interpretable results, improving accuracy and logical consistency."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"NLP"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PyTorch"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Symbolic Reasoning"}],["$","span","4",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computer Vision"}]]}]]}],["$","$L2","1",{"href":"https://github.com/aya0221/Object-Tracking-Under-Occlusions","className":"group p-6 rounded-lg border bg-card hover-lift colorful-border","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Object Tracking Under Occlusions"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Built a robust object tracking system combining CNN-based detection and Kalman filters to predict and track occluded objects effectively. Developed using ResNet for feature extraction and applied in scenarios requiring real-time, accurate tracking under challenging visual conditions."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Kalman Filter (Mathematical Modeling)"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Object Tracking"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"ResNet"}]]}]]}]]}]]}],["$","section",null,{"className":"space-y-8","children":[["$","h2",null,{"className":"text-2xl font-semibold","children":"Experience"}],["$","div",null,{"className":"space-y-12","children":[["$","div","0",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"Open Source Contributor"}],["$","p",null,{"className":"text-muted-foreground","children":"Python Typed APIs Project - Supervised by Prof. Kamen Yotov"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2024 - Present"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developing type-safe Python clients for widely-used services in an open-source project, automating API generation to address gaps in the software development industry."]}]]}]]}],["$","div","1",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"Research Assistant"}],["$","p",null,{"className":"text-muted-foreground","children":"Neuroscience Kiani Lab, NYU Center for Neural Science"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2023"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Contributed 5k+ eye-tracking data as a subject for the lab's decision-making experiments."]}],["$","li","1",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developed a DeepDream algorithm using pre-trained CNNs (ResNet/VGG-16) to generate dream-like images, aiming for future use in neural decision-making experiments on primates."]}],["$","li","2",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Gained insights into research methodologies and expanded knowledge of neuroscience."]}]]}]]}],["$","div","2",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"AI Robotics Engineer"}],["$","p",null,{"className":"text-muted-foreground","children":"Nihon Business Data Processing Center"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2021 - 2022"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developed and deployed a voice-to-motion robotics system showcased to 10k+ exhibition visitors, leading the AI development as the sole AI engineer on a team of 5."]}],["$","li","1",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Integrated voice recognition (Julius/SRILM) and speech synthesis (JACK/OpenJTalk) into the robot, enabling seamless interaction between humans and robots."]}],["$","li","2",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Researched NLP for the future voice chatbot product, adjusting pre-trained models (BERT/GPT2/Blender), developing original small models (LSTM), and preprocessing messy 400kb data (MeCab/NLTK)."]}],["$","li","3",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Played a project management role, leading cross-functional collaboration, timelines, and deployment strategies."]}]]}]]}]]}]]}]]}]}],null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/41e07592a33747ee.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_0aa4ae font-sans","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L3",null,{}],["$","main",null,{"className":"flex-1 w-full max-w-4xl mx-auto px-4","children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}],["$","footer",null,{"className":"py-8","children":["$","div",null,{"className":"container flex flex-col items-center space-y-8","children":[["$","div",null,{"className":"flex items-center space-x-10","children":[["$","$L2",null,{"href":"mailto:ayaoshima.us@gmail.com","className":"bg-green-500 text-white rounded-full p-6 hover:bg-green-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-mail h-10 w-10","children":[["$","rect","18n3k1",{"width":"20","height":"16","x":"2","y":"4","rx":"2"}],["$","path","1ocrg3",{"d":"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"Email"}]]}],["$","$L2",null,{"href":"https://github.com/aya0221","className":"bg-blue-500 text-white rounded-full p-6 hover:bg-blue-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-github h-10 w-10","children":[["$","path","tonef",{"d":"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"}],["$","path","9comsn",{"d":"M9 18c-4.51 2-5-2-7-2"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"GitHub"}]]}],["$","$L2",null,{"href":"https://www.linkedin.com/in/ayaoshima","className":"bg-green-500 text-white rounded-full p-6 hover:bg-green-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-linkedin h-10 w-10","children":[["$","path","c2jq9f",{"d":"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"}],["$","rect","mk3on5",{"width":"4","height":"12","x":"2","y":"9"}],["$","circle","bt5ra8",{"cx":"4","cy":"4","r":"2"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"LinkedIn"}]]}]]}],["$","p",null,{"className":"text-green-500 font-bold text-sm","children":"COPYRIGHT AYAOSHIMA 2024"}]]}]}]," "]}]}]}]],null],null],["$L6",null]]]]
6:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Aya Oshima - AI Engineer"}],["$","meta","3",{"name":"description","content":"AI Engineer specializing in ML, Robotics, and Full-stack Development"}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
