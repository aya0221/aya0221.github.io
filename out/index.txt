2:I[2972,["972","static/chunks/972-b2019802b076e131.js","931","static/chunks/app/page-d945f7a24654736b.js"],""]
3:I[2798,["972","static/chunks/972-b2019802b076e131.js","373","static/chunks/373-c9d94647dd4aeee5.js","876","static/chunks/876-e00645a8fdf64d5b.js","185","static/chunks/app/layout-0ed60b5196d7bd4b.js"],"ThemeProvider"]
4:I[6088,["972","static/chunks/972-b2019802b076e131.js","373","static/chunks/373-c9d94647dd4aeee5.js","876","static/chunks/876-e00645a8fdf64d5b.js","185","static/chunks/app/layout-0ed60b5196d7bd4b.js"],"Navigation"]
5:I[4707,[],""]
6:I[6423,[],""]
7:I[3284,["972","static/chunks/972-b2019802b076e131.js","373","static/chunks/373-c9d94647dd4aeee5.js","876","static/chunks/876-e00645a8fdf64d5b.js","185","static/chunks/app/layout-0ed60b5196d7bd4b.js"],"Footer"]
0:["FSejKlqBp5MH3kk9BZgJl",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","div",null,{"className":"pt-32 pb-16","children":["$","div",null,{"className":"container space-y-32","children":[["$","section",null,{"className":"max-w-4xl","children":["$","h1",null,{"className":"text-6xl font-bold mb-8","children":["Hi! I'm ",["$","span",null,{"className":"gradient-text","children":"Aya Oshima"}],", an AI engineer based in New York."]}]}],["$","section",null,{"className":"space-y-8","children":[["$","h2",null,{"className":"text-2xl font-semibold","children":"Selected Work"}],["$","div",null,{"className":"p-6 rounded-lg border bg-card hover-lift colorful-border flex flex-col md:flex-row gap-4","children":[["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Thesis: Dimensional Reduction Techniques for Neural Data"}],["$","$L2",null,{"href":"https://aya0221.github.io/thesis-pdf/thesis_ayaoshima.pdf","target":"_blank","className":"group-hover:text-primary transition-colors","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Explored dimensional reduction techniques (PCA, TCA) applied to large-scale neural datasets. Conducted analysis on complex neural patterns, providing insights into brain activity and computational neuroscience, under the guidance of Prof. Robert C. Froemke."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Statistical Modeling"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PCA"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"TCA"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computational Neuroscience"}],["$","span","4",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Data Analysis"}],["$","span","5",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Dimension Reduction"}],["$","span","6",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Matlab"}],["$","span","7",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Python"}]]}]]}],["$","div",null,{"className":"flex flex-col flex-1 gap-4","children":[["$","img",null,{"src":"/images/thesis_demo.jpg","alt":"Thesis Image 1","className":"w-full h-auto rounded-lg shadow-md"}],["$","img",null,{"src":"/images/thesis_demo_paper1.jpg","alt":"Thesis Image 2","className":"w-full h-auto rounded-lg shadow-md"}]]}]]}],["$","div",null,{"className":"grid gap-8 md:grid-cols-2","children":[["$","$L2","0",{"href":"https://github.com/aya0221/Neural-Symbolic-VQA-Sort-of-CLEVR","target":"_blank","rel":"noopener noreferrer","className":"group p-6 rounded-lg border bg-card hover-lift colorful-border","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Neural-Symbolic VQA"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Designed a multi-modal AI system integrating computer vision, NLP, and symbolic reasoning to enhance visual question answering on the Sort-of-CLEVR dataset. Leveraged PyTorch to implement CNNs for image processing and integrated symbolic reasoning to provide interpretable results, improving accuracy and logical consistency."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Multi-Modal"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computer Vision"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"NLP"}],["$","span","4",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PyTorch"}],["$","span","5",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Symbolic Reasoning"}],["$","span","6",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Python"}]]}]]}],["$","$L2","1",{"href":"https://github.com/aya0221/Object-Tracking-Under-Occlusions","target":"_blank","rel":"noopener noreferrer","className":"group p-6 rounded-lg border bg-card hover-lift colorful-border","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Object Tracking Under Occlusions"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Built a robust object tracking system combining CNN-based detection and Kalman filters to predict and track occluded objects effectively. Developed using ResNet for feature extraction and applied in scenarios requiring real-time, accurate tracking under challenging visual conditions."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Mathematical Modeling"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Kalman Filter"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Object Tracking"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","4",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"ResNet"}],["$","span","5",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Python"}]]}]]}]]}]]}],["$","section",null,{"className":"space-y-8","children":[["$","h2",null,{"className":"text-2xl font-semibold","children":"Experience"}],["$","div",null,{"className":"space-y-12","children":[["$","div","0",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"Open Source Contributor"}],["$","p",null,{"className":"text-muted-foreground","children":"Python Typed APIs Project - Supervised by Prof. Kamen Yotov"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2024 - Present"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developing type-safe Python clients for widely-used services in an open-source project, automating API generation to address gaps in the software development industry."]}]]}]]}],["$","div","1",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"Research Assistant"}],["$","p",null,{"className":"text-muted-foreground","children":"Neuroscience Kiani Lab, NYU Center for Neural Science"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2023"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Contributed 5k+ eye-tracking data as a subject for the lab's decision-making experiments."]}],["$","li","1",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developed a DeepDream algorithm using pre-trained CNNs (ResNet/VGG-16) to generate dream-like images, aiming for future use in neural decision-making experiments on primates."]}],["$","li","2",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Gained insights into research methodologies and expanded knowledge of neuroscience."]}]]}]]}],["$","div","2",{"className":"group","children":[["$","div",null,{"className":"flex justify-between items-start mb-2","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-primary","children":"AI Robotics Engineer"}],["$","p",null,{"className":"text-muted-foreground","children":"Nihon Business Data Processing Center"}]]}],["$","span",null,{"className":"text-muted-foreground","children":"2021 - 2022"}]]}],["$","ul",null,{"className":"pl-6 text-muted-foreground space-y-2","children":[["$","li","0",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Developed and deployed a voice-to-motion robotics system showcased to 10k+ exhibition visitors, leading the AI development as the sole AI engineer on a team of 5."]}],["$","li","1",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Integrated voice recognition (Julius/SRILM) and speech synthesis (JACK/OpenJTalk) into the robot, enabling seamless interaction between humans and robots."]}],["$","li","2",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Researched NLP for the future voice chatbot product, adjusting pre-trained models (BERT/GPT2/Blender), developing original small models (LSTM), and preprocessing messy 400kb data (MeCab/NLTK)."]}],["$","li","3",{"className":"relative pl-6","children":[["$","span",null,{"className":"absolute left-0 text-primary","children":"-"}],"Played a project management role, leading cross-functional collaboration, timelines, and deployment strategies."]}]]}]]}]]}]]}]]}]}],null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/1d8967eb8bcb845c.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_0aa4ae font-sans","children":["$","$L3",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L4",null,{}],["$","main",null,{"className":"flex-1 w-full max-w-4xl mx-auto px-4","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}],["$","$L7",null,{}]," "]}]}]}]}]],null],null],["$L8",null]]]]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Aya Oshima - AI Engineer"}],["$","meta","3",{"name":"description","content":"AI Engineer specializing in ML, Robotics, and Full-stack Development"}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
