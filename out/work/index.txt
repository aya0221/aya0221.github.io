2:I[5878,["878","static/chunks/878-4218b8fc1050f006.js","534","static/chunks/app/work/page-e076b5abd246d4b7.js"],"Image"]
3:I[4707,[],""]
4:I[6423,[],""]
5:I[8599,["972","static/chunks/972-edd2ee9795e590ec.js","598","static/chunks/598-ebaef4f280efd328.js","185","static/chunks/app/layout-eb753ae0993d2b16.js"],"Navigation"]
6:I[2972,["972","static/chunks/972-edd2ee9795e590ec.js","931","static/chunks/app/page-d945f7a24654736b.js"],""]
0:["uOXOE3E1eJgAh3FS7zC1a",[[["",{"children":["work",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",{"children":["work",{"children":["__PAGE__",{},[["$L1",["$","div",null,{"className":"pt-32 pb-16","children":["$","div",null,{"className":"container max-w-4xl space-y-16","children":[["$","section",null,{"className":"space-y-8","children":[["$","h1",null,{"className":"text-4xl font-bold gradient-text","children":"Selected Work"}],["$","p",null,{"className":"text-lg text-muted-foreground","children":"A collection of projects that showcase my expertise in AI, machine learning, and computational neuroscience."}]]}],["$","section",null,{"className":"space-y-16","children":[["$","div","0",{"className":"p-6 rounded-lg border bg-card hover-lift colorful-border flex flex-col md:flex-row gap-4","children":[["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Dimensional Reduction for Neuron Data"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-file-text w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1rqfz7",{"d":"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"}],["$","path","tnqrlb",{"d":"M14 2v4a2 2 0 0 0 2 2h4"}],["$","path","b1mrlr",{"d":"M10 9H8"}],["$","path","t4e002",{"d":"M16 13H8"}],["$","path","z1uh3a",{"d":"M16 17H8"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Explored dimensional reduction techniques (PCA, TCA) applied to large-scale neural datasets. Conducted analysis on complex neural patterns, providing insights into brain activity and computational neuroscience."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PCA"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"TCA"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computational Neuroscience"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Data Analysis"}]]}]]}],["$","div",null,{"className":"flex flex-col flex-1 gap-4","children":[["$","$L2","0",{"src":"/images/thesis_demo.jpg","alt":"Dimensional Reduction for Neuron Data Image 1","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}],["$","$L2","1",{"src":"/images/thesis_demo_paper1.jpg","alt":"Dimensional Reduction for Neuron Data Image 2","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}]]}]]}],["$","div","1",{"className":"p-6 rounded-lg border bg-card hover-lift colorful-border flex flex-col md:flex-row gap-4","children":[["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Neural-Symbolic VQA"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Designed a multi-modal AI system integrating computer vision, NLP, and symbolic reasoning to enhance visual question answering on the Sort-of-CLEVR dataset. Achieved high accuracy in both relational and non-relational questions."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"NLP"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"PyTorch"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Symbolic Reasoning"}],["$","span","4",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Computer Vision"}]]}]]}],["$","div",null,{"className":"flex flex-col flex-1 gap-4","children":[["$","$L2","0",{"src":"/images/vqa_demophoto.jpg","alt":"Neural-Symbolic VQA Image 1","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}],["$","$L2","1",{"src":"/images/vqa_techphoto.jpg","alt":"Neural-Symbolic VQA Image 2","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}]]}]]}],["$","div","2",{"className":"p-6 rounded-lg border bg-card hover-lift colorful-border flex flex-col md:flex-row gap-4","children":[["$","div",null,{"className":"flex-1","children":[["$","div",null,{"className":"flex justify-between items-start mb-4","children":[["$","h3",null,{"className":"text-xl font-semibold","children":"Object Tracking Under Occlusions"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-up-right w-5 h-5 text-muted-foreground group-hover:text-primary transition-colors","children":[["$","path","1tivn9",{"d":"M7 7h10v10"}],["$","path","1vkiza",{"d":"M7 17 17 7"}],"$undefined"]}]]}],["$","p",null,{"className":"text-muted-foreground mb-4","children":"Built a robust object tracking system combining CNN-based detection and Kalman filters to predict and track occluded objects effectively. Developed using ResNet for feature extraction, enabling accurate tracking under challenging conditions."}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","0",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"CNN"}],["$","span","1",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Kalman Filter (Mathematical Modeling)"}],["$","span","2",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"Object Tracking"}],["$","span","3",{"className":"text-sm px-3 py-1 rounded-full bg-muted text-muted-foreground","children":"ResNet"}]]}]]}],["$","div",null,{"className":"flex flex-col flex-1 gap-4","children":[["$","$L2","0",{"src":"/images/ballpic.jpg","alt":"Object Tracking Under Occlusions Image 1","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}],["$","$L2","1",{"src":"/images/objDetection_ballpic.jpg","alt":"Object Tracking Under Occlusions Image 2","width":800,"height":600,"className":"w-full h-auto rounded-lg shadow-md"}]]}]]}]]}]]}]}],null],null],null]},[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","work","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/41e07592a33747ee.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_0aa4ae font-sans","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L5",null,{}],["$","main",null,{"className":"flex-1 w-full max-w-4xl mx-auto px-4","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}],["$","footer",null,{"className":"py-8","children":["$","div",null,{"className":"container flex flex-col items-center space-y-8","children":[["$","div",null,{"className":"flex items-center space-x-10","children":[["$","$L6",null,{"href":"mailto:ayaoshima.us@gmail.com","className":"bg-green-500 text-white rounded-full p-6 hover:bg-green-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-mail h-10 w-10","children":[["$","rect","18n3k1",{"width":"20","height":"16","x":"2","y":"4","rx":"2"}],["$","path","1ocrg3",{"d":"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"Email"}]]}],["$","$L6",null,{"href":"https://github.com/aya0221","className":"bg-blue-500 text-white rounded-full p-6 hover:bg-blue-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-github h-10 w-10","children":[["$","path","tonef",{"d":"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"}],["$","path","9comsn",{"d":"M9 18c-4.51 2-5-2-7-2"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"GitHub"}]]}],["$","$L6",null,{"href":"https://www.linkedin.com/in/ayaoshima","className":"bg-green-500 text-white rounded-full p-6 hover:bg-green-600 transition-transform transform hover:scale-125 shadow-lg","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-linkedin h-10 w-10","children":[["$","path","c2jq9f",{"d":"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"}],["$","rect","mk3on5",{"width":"4","height":"12","x":"2","y":"9"}],["$","circle","bt5ra8",{"cx":"4","cy":"4","r":"2"}],"$undefined"]}],["$","span",null,{"className":"sr-only","children":"LinkedIn"}]]}]]}],["$","p",null,{"className":"text-green-500 font-bold text-sm","children":"COPYRIGHT AYAOSHIMA 2024"}]]}]}]," "]}]}]}]],null],null],["$L7",null]]]]
7:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Aya Oshima - AI Engineer"}],["$","meta","3",{"name":"description","content":"AI Engineer specializing in ML, Robotics, and Full-stack Development"}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
